{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "\n",
    "Ensembles são conjunto de estimadores. A ideia geral é que a opinião de um grupo é normalmente mais forte que a opinião de um único indíviduo. Em uma comparação com fins didáticos, é como se um modelo estivesse tomando uma decisão com base na opinião de vários experts.\n",
    "<br>\n",
    "Formalmente, usa-se vários estimadores bases para compor conjuntos de estimadores que irão realizar o processo de machine learning.\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "* Em geral, aumento de precisão\n",
    "    * Pode transformar um *weak learner* em um *strong learner*\n",
    "\n",
    "**Desvantangens:**\n",
    "\n",
    "* Perda de poder de interpretação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=1000, n_features=20,\n",
    "                                   n_informative=2, n_redundant=10,\n",
    "                                   random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                   random_state=42)\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifiers = [XGBClassifier(), ExtraTreesClassifier(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "names = ['Xgboost', 'Extremely Randomized Trees', 'Random Forest', 'Gradient Tree Boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Xgboost = 0.91 [+/- 0.02]\n",
      "Acurácia do Extremely Randomized Trees = 0.91 [+/- 0.03]\n",
      "Acurácia do Random Forest = 0.91 [+/- 0.02]\n",
      "Acurácia do Gradient Tree Boosting = 0.91 [+/- 0.02]\n"
     ]
    }
   ],
   "source": [
    "def train_and_test(clf, name):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "    print('Acurácia do %s = %.2f [+/- %.2f]' % (name, scores.mean(), scores.std()))\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    train_and_test(clf, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de parâmetros de Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier() \n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 8.9254628154897002, 'learning_rate': 0.34790503714318155, 'max_depth': 16, 'n_estimators': 100}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=8.9254628154897002,\n",
      "       learning_rate=0.34790503714318155, max_delta_step=0, max_depth=16,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "0.917142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rs = RandomizedSearchCV(xgb, params, n_jobs=-1, cv=10, n_iter=10)  \n",
    "rs.fit(X_train, y_train) \n",
    "print(rs.best_params_)\n",
    "print(rs.best_estimator_)\n",
    "print(rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Materiais para estudo:\n",
    "\n",
    "* [Gradient Tree Boosting](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "* [Extremely randomized trees](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)\n",
    "* [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [Xgboost](https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/)\n",
    "\n",
    "**Papers dos algoritmso citados:**\n",
    "\n",
    "* Hastie, T.; Friedman, J.; Tibshirani, R. **Boosting and additive trees.** In: The Elements of Statistical Learning. [S.l.]: Springer, 2001. p. 299–345. Citado na página 24.\n",
    "* Geurts, Pierre, Damien Ernst, and Louis Wehenkel. **\"Extremely randomized trees.\"** Machine learning 63.1 (2006): 3-42.    \n",
    "* Breiman, Leo. **\"Random forests.\"** Machine learning 45.1 (2001): 5-32.    \n",
    "* Chen, Tianqi, and Carlos Guestrin. **\"Xgboost: A scalable tree boosting system.\"** Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. ACM, 2016.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
