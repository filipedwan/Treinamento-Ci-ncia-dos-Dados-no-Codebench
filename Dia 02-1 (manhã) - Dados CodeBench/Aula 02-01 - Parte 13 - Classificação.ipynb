{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('figure', figsize = (20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizacao(df):\n",
    "    from sklearn import preprocessing\n",
    "    np_scaled = preprocessing.scale(df)\n",
    "    df_normalized = pd.DataFrame(np_scaled, columns = df.columns)\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretizacao_das_medias(df):\n",
    "    df.loc[df.Media_Final<5.0, 'Media_Final'] = 0\n",
    "    df.loc[df.Media_Final>=5.0, 'Media_Final'] = 1\n",
    "    df['Media_Final'] = df.Media_Final.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subamostragem_balanceamento(df):\n",
    "    g = df.groupby('Media_Final')\n",
    "    df = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempts</th>\n",
       "      <th>comments</th>\n",
       "      <th>blank_line</th>\n",
       "      <th>lloc</th>\n",
       "      <th>sloc</th>\n",
       "      <th>single_comments</th>\n",
       "      <th>system_access</th>\n",
       "      <th>exam_grade_codebench</th>\n",
       "      <th>difficult</th>\n",
       "      <th>delete_average</th>\n",
       "      <th>...</th>\n",
       "      <th>submission_per_exercice</th>\n",
       "      <th>sucess_average</th>\n",
       "      <th>test_average</th>\n",
       "      <th>exercices_list_grade</th>\n",
       "      <th>exercices_list_grade_check_plagiarism</th>\n",
       "      <th>copy_past_proportion</th>\n",
       "      <th>sintaxe_error</th>\n",
       "      <th>IDE_usage</th>\n",
       "      <th>keystroke_latency</th>\n",
       "      <th>Media_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.057293</td>\n",
       "      <td>-0.314933</td>\n",
       "      <td>-0.339140</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>-0.026467</td>\n",
       "      <td>-0.310231</td>\n",
       "      <td>2.191555</td>\n",
       "      <td>1.501286</td>\n",
       "      <td>-1.113019</td>\n",
       "      <td>-0.079093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163582</td>\n",
       "      <td>0.140087</td>\n",
       "      <td>-0.298199</td>\n",
       "      <td>0.671344</td>\n",
       "      <td>1.176323</td>\n",
       "      <td>-0.129364</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>-0.002542</td>\n",
       "      <td>0.524059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.314589</td>\n",
       "      <td>-0.321891</td>\n",
       "      <td>0.555079</td>\n",
       "      <td>0.423888</td>\n",
       "      <td>0.378353</td>\n",
       "      <td>-0.317618</td>\n",
       "      <td>0.099887</td>\n",
       "      <td>-0.591623</td>\n",
       "      <td>0.029113</td>\n",
       "      <td>0.380139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117493</td>\n",
       "      <td>0.140087</td>\n",
       "      <td>0.346478</td>\n",
       "      <td>0.671344</td>\n",
       "      <td>0.292288</td>\n",
       "      <td>-0.125731</td>\n",
       "      <td>-0.843827</td>\n",
       "      <td>0.442080</td>\n",
       "      <td>0.685042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314589</td>\n",
       "      <td>-0.321891</td>\n",
       "      <td>0.555079</td>\n",
       "      <td>0.423888</td>\n",
       "      <td>0.378353</td>\n",
       "      <td>-0.317618</td>\n",
       "      <td>-1.130506</td>\n",
       "      <td>-1.255840</td>\n",
       "      <td>0.926502</td>\n",
       "      <td>-0.800742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300507</td>\n",
       "      <td>-0.993536</td>\n",
       "      <td>-0.771065</td>\n",
       "      <td>-1.984898</td>\n",
       "      <td>-1.478438</td>\n",
       "      <td>-0.132266</td>\n",
       "      <td>1.992557</td>\n",
       "      <td>-1.023294</td>\n",
       "      <td>-1.662622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046008</td>\n",
       "      <td>-0.342767</td>\n",
       "      <td>-0.335722</td>\n",
       "      <td>-0.108619</td>\n",
       "      <td>-0.136758</td>\n",
       "      <td>-0.339780</td>\n",
       "      <td>-0.515310</td>\n",
       "      <td>1.087717</td>\n",
       "      <td>0.702154</td>\n",
       "      <td>0.694384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160547</td>\n",
       "      <td>-0.615661</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>0.376501</td>\n",
       "      <td>0.881645</td>\n",
       "      <td>-0.132048</td>\n",
       "      <td>-0.376291</td>\n",
       "      <td>0.686309</td>\n",
       "      <td>0.859440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.528343</td>\n",
       "      <td>-0.153150</td>\n",
       "      <td>-0.492922</td>\n",
       "      <td>-0.460118</td>\n",
       "      <td>-0.455334</td>\n",
       "      <td>-0.138479</td>\n",
       "      <td>0.099887</td>\n",
       "      <td>-1.005192</td>\n",
       "      <td>-1.337366</td>\n",
       "      <td>-0.557787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216982</td>\n",
       "      <td>1.308061</td>\n",
       "      <td>-0.521862</td>\n",
       "      <td>0.671344</td>\n",
       "      <td>-0.299724</td>\n",
       "      <td>-0.127738</td>\n",
       "      <td>-0.812658</td>\n",
       "      <td>-0.741491</td>\n",
       "      <td>0.081357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attempts  comments  blank_line      lloc      sloc  single_comments  \\\n",
       "0 -0.057293 -0.314933   -0.339140  0.002727 -0.026467        -0.310231   \n",
       "1  0.314589 -0.321891    0.555079  0.423888  0.378353        -0.317618   \n",
       "2  0.314589 -0.321891    0.555079  0.423888  0.378353        -0.317618   \n",
       "3  0.046008 -0.342767   -0.335722 -0.108619 -0.136758        -0.339780   \n",
       "4 -0.528343 -0.153150   -0.492922 -0.460118 -0.455334        -0.138479   \n",
       "\n",
       "   system_access  exam_grade_codebench  difficult  delete_average  \\\n",
       "0       2.191555              1.501286  -1.113019       -0.079093   \n",
       "1       0.099887             -0.591623   0.029113        0.380139   \n",
       "2      -1.130506             -1.255840   0.926502       -0.800742   \n",
       "3      -0.515310              1.087717   0.702154        0.694384   \n",
       "4       0.099887             -1.005192  -1.337366       -0.557787   \n",
       "\n",
       "      ...       submission_per_exercice  sucess_average  test_average  \\\n",
       "0     ...                      0.163582        0.140087     -0.298199   \n",
       "1     ...                      0.117493        0.140087      0.346478   \n",
       "2     ...                     -0.300507       -0.993536     -0.771065   \n",
       "3     ...                     -0.160547       -0.615661      0.028396   \n",
       "4     ...                     -0.216982        1.308061     -0.521862   \n",
       "\n",
       "   exercices_list_grade  exercices_list_grade_check_plagiarism  \\\n",
       "0              0.671344                               1.176323   \n",
       "1              0.671344                               0.292288   \n",
       "2             -1.984898                              -1.478438   \n",
       "3              0.376501                               0.881645   \n",
       "4              0.671344                              -0.299724   \n",
       "\n",
       "   copy_past_proportion  sintaxe_error  IDE_usage  keystroke_latency  \\\n",
       "0             -0.129364      -0.002262  -0.002542           0.524059   \n",
       "1             -0.125731      -0.843827   0.442080           0.685042   \n",
       "2             -0.132266       1.992557  -1.023294          -1.662622   \n",
       "3             -0.132048      -0.376291   0.686309           0.859440   \n",
       "4             -0.127738      -0.812658  -0.741491           0.081357   \n",
       "\n",
       "   Media_Final  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/session3.csv')\n",
    "df.loc[:, df.columns != 'Media_Final'] = normalizacao(df.loc[:, df.columns != 'Media_Final'])\n",
    "df = discretizacao_das_medias(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media_Final\n",
       "0    162\n",
       "1    210\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.groupby('Media_Final')\n",
    "g.size()\n",
    "#Caso queira realizar subamostragem, basta executar o comando abaixo:\n",
    "#df = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os atributos das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = df.drop('Media_Final', axis=1).values, df['Media_Final'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#pipeline = make_pipeline(\n",
    "#            RFE(estimator=ExtraTreesClassifier(criterion=\"gini\", n_estimators=100), step=0.5),\n",
    "#            RandomForestClassifier(max_features=0.9500000000000001, min_samples_leaf=20, n_estimators=500)\n",
    "#        )\n",
    "\n",
    "pipeline = ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.45, min_samples_leaf=7, min_samples_split=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score = cross_val_score(pipeline, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc.: 0.73 [+/-0.08]\n"
     ]
    }
   ],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusÃ£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb512402b38>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHwCAYAAABHU3CkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xvc5/Wc//HHc2Y6l5pMRedQqRA1JSwKS61W8VupdQjZ\nfmzsIdav8BNrWy3W4idrHVKJUoQoJTlEmzRSNOismkozY3RQmZrp9fvj+5n2asxc12euru/1vebz\nfdzdvre5vu/P5/v5vL8XY1635/vwSVUhSZI0zKYNugOSJEmDZkEkSZKGngWRJEkaehZEkiRp6FkQ\nSZKkoWdBJEmShp4FkTRgSdZJ8o0kdyY54xFc55VJvj2RfRuEJN9Kcuig+yFpuFgQSS0l+eskc5L8\nIcltzT/cfzYBl/4rYDPg0VX18vFepKq+UFUvnID+PEySvZNUkq8u175r0/79ltd5T5JTxjqvqvar\nqpPG2V1JGhcLIqmFJEcCHwH+lV7xsjVwPPCSCbj8NsDVVbVkAq7VLwuAZyR59Ii2Q4GrJ+oG6fH/\nkyQNhP/nI40hyYbAPwNHVNWZVXVPVT1QVd+sqrc356yV5CNJbm1eH0myVnNs7yTzkrw1yfwmXXpd\nc+y9wLuBVzTJ02HLJylJtm2SmBnN+9cmuT7J3UluSPLKEe0/GvG5Zya5tBmKuzTJM0cc+36S9yW5\nqLnOt5PMGuXXcD/wNeDg5vPTgVcAX1jud/XRJDcnuSvJT5M8u2nfF3jHiO95xYh+HJvkIuBe4HFN\n2xua4/+Z5Csjrv9vSS5Iktb/BUpSCxZE0tieAawNfHWUc94J7AU8FdgV2BN414jjjwE2BLYADgOO\nTzKzqo6hlzp9qarWr6rPjtaRJOsBHwP2q6oNgGcCl6/gvI2Bs5tzHw18GDh7uYTnr4HXAZsCawJv\nG+3ewMnAa5qfXwRcCdy63DmX0vsdbAx8ETgjydpVde5y33PXEZ95NXA4sAFw43LXeyvw5KbYeza9\n392h5TOHJE0wCyJpbI8GFo4xpPVK4J+ran5VLQDeS+8f+mUeaI4/UFXnAH8Adhxnfx4EnpRknaq6\nrarmruCcFwPXVNXnq2pJVZ0K/Br4yxHnfK6qrq6q+4DT6RUyK1VV/w1snGRHeoXRySs455Sq+l1z\nz38H1mLs73liVc1tPvPActe7l97v8cPAKcBbqmreGNeTpFVmQSSN7XfArGVDViuxOQ9PN25s2h66\nxnIF1b3A+qvakaq6h95Q1RuB25KcneSJLfqzrE9bjHj/23H05/PAm4F9WEFiluRtSX7VDNPdQS8V\nG20oDuDm0Q5W1SXA9UDoFW6SNOEsiKSxXQwsBg4c5Zxb6U2OXmZr/nQ4qa17gHVHvH/MyINVdV5V\n/TnwWHqpz6db9GdZn24ZZ5+W+Tzwt8A5TXrzkGZI6+3AQcDMqtoIuJNeIQOwsmGuUYe/khxBL2m6\ntbm+JE04CyJpDFV1J72Jz8cnOTDJuknWSLJfkg80p50KvCvJJs3k5HfTG+IZj8uB5yTZupnQffSy\nA0k2S3JAM5doMb2htwdXcI1zgB2arQJmJHkFsDPwzXH2CYCqugF4Lr05U8vbAFhCb0XajCTvBh41\n4vjtwLarspIsyQ7AvwCvojd09vYkow7tSdJ4WBBJLTTzYY6kN1F6Ab1hnjfTW3kFvX+05wA/B34B\nXNa0jede5wNfaq71Ux5exExr+nErsIhecfKmFVzjd8D+9CYl/45esrJ/VS0cT5+Wu/aPqmpF6dd5\nwLn0luLfCPyRhw+HLdt08ndJLhvrPs0Q5SnAv1XVFVV1Db2Vap9ftoJPkiZKXKwhSZKGnQmRJEka\nehZEkiRp6FkQSZKkoWdBJEmShp4FkSRJGnqj7bw76dbeYGatt8nmY58oaVy23HDtQXdB6rSbb7qR\nRb9b2NmHD09/1DZVS+6b8OvWfQvOq6p9J/zCq2BKFUTrbbI5L37fFwfdDamzjnvxToPugtRp++3z\njEF3oa9qyX2steNBE37dP15+/FiP+Om7KVUQSZKkqSzQfrP51Uo3v5UkSdIqMCGSJEntBEg3p0iZ\nEEmSpKFnQiRJktrr6BwiCyJJktSeQ2aSJEndZEIkSZJactm9JElSZ5kQSZKk9jo6h8iCSJIktRMc\nMpMkSeoqEyJJktRSOjtkZkIkSZKGngmRJElqr6NziCyIJElSew6ZSZIkdZMJkSRJasmdqiVJkjrL\nhEiSJLUTnEMkSZLUVSZEkiSpvY7OIbIgkiRJLTmpWpIkqbNMiCRJUnvTnFQtSZI06ZKckGR+kiuX\na39Lkl8nmZvkAyPaj05ybZKrkryozT1MiCRJUjthUHOITgQ+Dpz8UFeSfYADgF2ranGSTZv2nYGD\ngV2AzYHvJNmhqpaOdgMTIkmS1F4y8a8xVNWFwKLlmt8EHFdVi5tz5jftBwCnVdXiqroBuBbYc6x7\nWBBJkqRBm5VkzojX4S0+swPw7CSXJPlBkj2a9i2Am0ecN69pG5VDZpIkqaW+LbtfWFWzV/EzM4CN\ngb2APYDTkzxuvB0wIZIkSaujecCZ1fMT4EFgFnALsNWI87Zs2kZlQSRJktobwByilfgasE+vS9kB\nWBNYCJwFHJxkrSTbAdsDPxnrYg6ZSZKk9gawyizJqcDe9OYazQOOAU4ATmiW4t8PHFpVBcxNcjrw\nS2AJcMRYK8zAgkiSJE1xVXXISg69aiXnHwscuyr3sCCSJEntPLIhrinNOUSSJGnomRBJkqT2Ovq0\newsiSZLUnkNmkiRJ3WRCJEmSWurbTtUD181vJUmStApMiCRJUnvOIZIkSeomEyJJktRO6OwcIgsi\nSZLUkpOqJUmSOsuESJIkteekakmSpG4yIZIkSe11dA6RBZEkSWrPITNJkqRuMiGSJEntxGX3kiRJ\nnWVCJEmS2uvoHCILIkmS1Fo6WhA5ZCZJkoaeCZEkSWolmBBJkiR1lgmRJElqJ82rg0yIJEnS0DMh\nkiRJLaWzc4gsiCRJUmtdLYgcMpMkSUPPhEiSJLVmQiRJktRRJkSSJKm1riZEFkSSJKkd9yGSJEnq\nLhMiSZLUSjq8D5EJkSRJGnomRJIkqbWuJkQWRJIkqbWuFkQOmUmSpKFnQiRJklozIZIkSeooEyJJ\nktSOGzNKkiR1lwmRJElqratziCyIJElSK+5ULUmS1GEmRJIkqTUTIkmSpI4yIZIkSe11MyCyIJIk\nSS3FITNJkqTOMiGSJEmtmRBJkiR1lAmRJElqrasJkQWRJElqxZ2qJUmSOsyESJIktdfNgMiESJIk\nyYRIkiS148aMkiRJg5HkhCTzk1y5gmNvTVJJZo1oOzrJtUmuSvKiNvewIJIkSa0lmfBXCycC+66g\nL1sBLwRuGtG2M3AwsEvzmU8kmT7WDSyIJElSa4MoiKrqQmDRCg79B/B2oEa0HQCcVlWLq+oG4Fpg\nz7HuYUEkSZIGbVaSOSNeh4/1gSQHALdU1RXLHdoCuHnE+3lN26icVC1Jktrrz5zqhVU1u3UXknWB\nd9AbLpsQFkSSJGl183hgO+CKZshtS+CyJHsCtwBbjTh3y6ZtVBZEkiSptamw7L6qfgFsuux9kt8A\ns6tqYZKzgC8m+TCwObA98JOxrmlBJEmSWlmFVWETfd9Tgb3pzTWaBxxTVZ9d0blVNTfJ6cAvgSXA\nEVW1dKx7WBBJkqQpraoOGeP4tsu9PxY4dlXuYUGklXrDXlvx1C024K4/LuEdZ18NwB5bb8hLn/wY\nNt9wLd577jXcsOi+h87ff5dNee7jN+bBKk6Zcyu/uO3uQXVdWi09/Sk7sP766zNt+nRmzJjBt753\nMe/7v0dx/nlns+Yaa7LNdo/jw8d/mg033GjQXdUQmwpDZv3Q12X3SfZtdom8NslR/byXJt4Pr1/E\nB797w8Pabrnjj3zswt9w1fx7Hta++aPWYq9tNuLob17FB797A6/ZYws6+ndG6qszvvFtzv/hpXzr\nexcD8Jx9ns93//tnfOein/K4x2/Pxz/8gQH3UOqmvhVEza6QxwP7ATsDhzS7R2o1cdX8e7jn/iUP\na7v1rsX89u7Ff3LublttyI9vvIMlDxYL77mf+Xffz+Mfve5kdVXqrOc+78+ZMaMX5u+2x9O57dYx\nF8tIfTWgnar7rp8J0Z7AtVV1fVXdD5xGb/dIddDMddZg0T33P/R+0b33M3OdNQbYI2n1k8ArDtyP\nfffei1NO/MyfHD/tlBPZ5wWtHssk9U/68JoC+jmHaEU7RT69j/eTpNXaV7/1PR67+RYsXDCfg1/6\nFzxh+x3Z61nPBuCjHzqOGTNm8LKDRp1bKmmcBv7ojiSHL9uqe/Fdvx90dzROv7/vATZeb82H3m+8\n7pr8/r4HBtgjafXz2M17TxeYtcmm7Lf/AVx+2aUAfOmLJ/Odb5/Dxz910pQZXtDwcshs1bXaKbKq\nPlVVs6tq9lqPmtnH7qiffjbvTvbaZiNmTAuz1luTzTZYk+t+d++guyWtNu695x7+cPfdD/38g+9+\nhx132oXvfec8/vNj/86JX/wK66zrvDypX/o5ZHYpsH2S7egVQgcDf93H+2mCvelZW7PTZuuz/loz\n+MhLd+LMn9/OPYuX8Oo9tmCDtWZw5N7bcdPv/8gHv3c9t9y5mEtuvIP3778jD1Zx8pxbqBr7HpJ6\nFiy4ncNedRAAS5cu4cD/dTD7vOBFPGu3nVi8+H4OfulfALDb7D35t/84fpBd1TBLd5fd960gqqol\nSd4MnAdMB06oqrn9up8m3n9edNMK2386764Vtn9j7ny+MXd+P7skddY22z6O7/xozp+0X3TZrwbQ\nG2n49HVjxqo6Bzinn/eQJEmTI9DZPebcqVqSJLU0dSZBT7SBrzKTJEkaNBMiSZLUWkcDIhMiSZIk\nEyJJktRaV+cQWRBJkqR24pCZJElSZ5kQSZKkVgJMm9bNiMiESJIkDT0TIkmS1FpX5xBZEEmSpNa6\nusrMITNJkjT0TIgkSVI7LruXJEnqLhMiSZLUSnAOkSRJUmeZEEmSpJbS2YTIgkiSJLXW0XrIITNJ\nkiQTIkmS1FpXh8xMiCRJ0tAzIZIkSe10eGNGCyJJktSK+xBJkiR1mAmRJElqraMBkQmRJEmSCZEk\nSWqtq3OILIgkSVJrHa2HHDKTJEkyIZIkSe2ku0NmJkSSJGnomRBJkqRWehszDroX/WFCJEmShp4J\nkSRJaimdnUNkQSRJklrraD3kkJkkSZIJkSRJaq2rQ2YmRJIkaeiZEEmSpHbS3TlEFkSSJKmV3j5E\n3ayIHDKTJElDz4RIkiS1ZkIkSZLUUSZEkiSptY4GRBZEkiSpPYfMJEmSOsqESJIktdPhfYhMiCRJ\n0tAzIZIkSa2EOIdIkiQpmfjX2PfMCUnmJ7lyRNsHk/w6yc+TfDXJRiOOHZ3k2iRXJXlRm+9lQSRJ\nkqa6E4F9l2s7H3hSVT0FuBo4GiDJzsDBwC7NZz6RZPpYN7AgkiRJrU1LJvw1lqq6EFi0XNu3q2pJ\n8/bHwJbNzwcAp1XV4qq6AbgW2HPM77UqvwRJkqQ+mJVkzojX4av4+dcD32p+3gK4ecSxeU3bqJxU\nLUmSWuvTnOqFVTV7PB9M8k5gCfCFR9IBCyJJkrRaSvJaYH/g+VVVTfMtwFYjTtuyaRuVQ2aSJKmV\n3qqwTPhrfH3JvsDbgZdU1b0jDp0FHJxkrSTbAdsDPxnreiZEkiSptWkD2IYoyanA3vTmGs0DjqG3\nqmwt4PymqPpxVb2xquYmOR34Jb2htCOqaulY97AgkiRJU1pVHbKC5s+Ocv6xwLGrcg8LIkmS1Jo7\nVUuSJHWUCZEkSWqtowGRBZEkSWon9B7w2kUOmUmSpKFnQiRJklobxLL7yWBCJEmShp4JkSRJaucR\n7Cw91VkQSZKk1jpaDzlkJkmSZEIkSZJaCTCtoxGRCZEkSRp6JkSSJKm1jgZEJkSSJEkmRJIkqTWX\n3UuSpKGWOGQmSZLUWSZEkiSpNZfdS5IkdZQJkSRJaq2b+ZAFkSRJWgVdXWXmkJkkSRp6K02Ikjxq\ntA9W1V0T3x1JkjRV9Z5lNuhe9MdoQ2ZzgeLhw4XL3hewdR/7JUmSNGlWWhBV1VaT2RFJkjTFJcM9\nhyjJwUne0fy8ZZLd+9stSZI0FS3brXoiX1PBmAVRko8D+wCvbpruBT7Zz05JkiRNpjbL7p9ZVbsl\n+RlAVS1Ksmaf+yVJkqagYR4yeyDJNHoTqUnyaODBvvZKkiRpErVJiI4HvgJskuS9wEHAe/vaK0mS\nNOUM67J7AKrq5CQ/BV7QNL28qq7sb7ckSZImT9tHd0wHHqA3bObu1pIkDamhnUOU5J3AqcDmwJbA\nF5Mc3e+OSZKkqSd9eE0FbRKi1wBPq6p7AZIcC/wMeH8/OyZJkjRZ2hREty133oymTZIkDZEEpnV0\nyGy0h7v+B705Q4uAuUnOa96/ELh0cronSZLUf6MlRMtWks0Fzh7R/uP+dUeSJE1lHQ2IRn2462cn\nsyOSJGnq6+oqszHnECV5PHAssDOw9rL2qtqhj/2SJEmaNG32FDoR+By9lXH7AacDX+pjnyRJ0hQ1\ntE+7B9atqvMAquq6qnoXvcJIkiSpE9osu1/cPNz1uiRvBG4BNuhvtyRJ0lQTMnzL7kf4R2A94O/o\nzSXaEHh9PzslSZKmoCk0xDXR2jzc9ZLmx7uBV/e3O5IkSZNvtI0Zv0pvI8YVqqqX9aVHkiRpyhrG\nZfcfn7ReNLaduQ6fesWuk31baWjM3OPNg+6C1GmLr7p50F3QOI22MeMFk9kRSZI09bVZnr466ur3\nkiRJaq3NKjNJkiTCcM4hepgka1XV4n52RpIkTW3TulkPjT1klmTPJL8Armne75rk//W9Z5IkSZOk\nzRyijwH7A78DqKorgH362SlJkjQ1TcvEv6aCNgXRtKq6cbm2pf3ojCRJ0iC0mUN0c5I9gUoyHXgL\ncHV/uyVJkqaa3tPpp0ikM8HaFERvojdstjVwO/Cdpk2SJA2ZqTLENdHaPMtsPnDwJPRFkiRpIMYs\niJJ8mhU806yqDu9LjyRJ0pTV0RGzVkNm3xnx89rASwEf1iJJkjqjzZDZl0a+T/J54Ed965EkSZqS\nAkzraEQ0nmeZbQdsNtEdkSRJU9+0PrzGkuSEJPOTXDmibeMk5ye5pvlz5ohjRye5NslVSV7U9nuN\n1YnfJ1nUvO4AzgeObnNxSZKkCXAisO9ybUcBF1TV9sAFzXuS7ExvMdguzWc+0WwbNKpRh8zS22xg\nV+CWpunBqvqTCdaSJGk4DGLErKouTLLtcs0HAHs3P58EfB/4P037ac3zV29Ici2wJ3DxaPcYNSFq\nip9zqmpp87IYkiRJE21WkjkjXm1Wsm9WVbc1P/+W/5nOswUPX/w1r2kbVZtVZpcneVpV/azFuZIk\nqaOS9GtS9cKqmj3eD1dVJXlEoc1KC6IkM6pqCfA04NIk1wH30JtkXlW12yO5sSRJ0iNwe5LHVtVt\nSR4LzG/abwG2GnHelvzP1J+VGi0h+gmwG/CS8fZUkiR1yxRadX8WcChwXPPn10e0fzHJh4HNge3p\n1TSjGq0gCkBVXfdIeitJkrpjEM8yS3IqvQnUs5LMA46hVwidnuQw4EbgIICqmpvkdOCXwBLgiKpa\nOtY9RiuINkly5MoOVtWH234RSZKk8aqqQ1Zy6PkrOf9Y4NhVucdoBdF0YH2apEiSJA23Lu9UPVpB\ndFtV/fOk9USSJGlAxpxDJEmStExHA6JRC6IVjstJkqQhlcFMqp4MK92puqoWTWZHJEmSBqXNTtWS\nJEkApKMzasZ82r0kSVLXmRBJkqRWesvuB92L/rAgkiRJrXW1IHLITJIkDT0TIkmS1Fo6uhGRCZEk\nSRp6JkSSJKmVLk+qNiGSJElDz4RIkiS1k+F8lpkkSdLDTOtoReSQmSRJGnomRJIkqRUnVUuSJHWY\nCZEkSWqto1OILIgkSVJbYRrdrIgcMpMkSUPPhEiSJLUSujtkZkIkSZKGngmRJElqJ91ddm9BJEmS\nWnOnakmSpI4yIZIkSa04qVqSJKnDTIgkSVJrziGSJEnqKBMiSZLUWkcDIgsiSZLUTuju0FJXv5ck\nSVJrJkSSJKmdQDo6ZmZCJEmShp4JkSRJaq2b+ZAFkSRJaim4D5EkSVJnmRBJkqTWupkPmRBJkiSZ\nEEmSpPY6OoXIgkiSJLUV9yGSJEnqKhMiSZLUis8ykyRJ6jATIkmS1JpziCRJkjrKhEiSJLXWzXzI\ngkiSJLUVh8wkSZI6y4RIkiS14rJ7SZKkDjMhkiRJrXV1DpEFkSRJaq2b5ZBDZpIkSSZEkiSpvY6O\nmJkQSZIkmRBJkqRWesvuuxkRmRBJkqTWkol/tbtv/jHJ3CRXJjk1ydpJNk5yfpJrmj9njvd7WRBJ\nkqQpLckWwN8Bs6vqScB04GDgKOCCqtoeuKB5Py4WRJIkqaX05T8tzQDWSTIDWBe4FTgAOKk5fhJw\n4Hi/mQWRJEkatFlJ5ox4HT7yYFXdAnwIuAm4Dbizqr4NbFZVtzWn/RbYbLwdcFK1JElqrU/L7hdW\n1eyV3zMz6aVB2wF3AGckedXIc6qqktR4O2BBJEmSWhngKrMXADdU1QKAJGcCzwRuT/LYqrotyWOB\n+eO9gUNmkiRpqrsJ2CvJuuk9TO35wK+As4BDm3MOBb4+3huYEEmSpHZWYZn8RKqqS5J8GbgMWAL8\nDPgUsD5wepLDgBuBg8Z7DwsiSZI05VXVMcAxyzUvppcWPWIWRJIkqTWfZSZJktRRJkSSJKm1VdhI\ncbViQSRJkloJMK2b9ZBDZpIkSSZEkiSpta4OmZkQSZKkoWdCJEmSWuvqsnsLIkmS1JpDZpIkSR1l\nQiRJklpx2b0kSVKHmRBJkqSW4hwiaenSpew1+2m87ID9AfjKl89gt113Yd01p/HTOXMG3Dtp9fPJ\nY17JjRe8nzlnvONh7W86+Llcfua7+OmX38mxf38AAGvMmM5/vedVXHr6O7jkS0fx7N23H0SXNezS\nW2U20a+poG8FUZITksxPcmW/7qHJ9fGPfZQdd9rpofe77PIkTjv9TP7s2c8ZYK+k1dfnv/FjDjji\n+Ie1PWf29uy/95PZ8xXHsftfHctHTr4AgNe/7FkA7HHQv7L/Gz/OcUe+lEyVf0mkDuhnQnQisG8f\nr69JNG/ePM791tm87vVveKjtiTvtxA477jjAXkmrt4suu45Fd977sLbDX/5sPvS587n/gSUALPj9\nHwB44uMew/cvveqhtjvvvo/dd956cjss0ZtYPdGvqaBvBVFVXQgs6tf1Nbn+6a3/wLHv/wDTpjnK\nKvXTE7bZlGc97fFcePLb+PZn/v6houcXV9/C/s99MtOnT2ObzR/N03beii0fM3PAvZW6w0nVGtM5\nZ3+TTTfZlN12350Lf/D9QXdH6rQZ06ex8Ybr8ZzXfIjZu2zDKR94PTvt/x5O+vrFPHG7zbjoC2/n\nptsW8eMrbmDp0gcH3V0Nmd6y+6mS6UysgRdESQ4HDgfYamvj36no4v++iG9+8yzOPfccFv/xj9x1\n11287jWv4nMnnzLorkmdc8vtd/C1Cy4HYM7cG3nwwWLWzPVZ+Ps/8PZ/P/Oh87534pFcc9P8QXVT\n6pyBj39U1aeqanZVzd5k1iaD7o5W4H3Hvp/rfjOPq679DSd/4TT23ud5FkNSn3zj+z/nuXvsAMAT\ntt6UNdeYwcLf/4F11l6DdddeE4DnPf2JLFn6IL++/reD7KqGVFfnEA08IdLq6+tf+ypH/sNbWLhg\nAS874MU8Zden8o1zzht0t6TVxknvfy3P3n17Zm20Ptee+z7e98lzOOlrF/Nf73klc854B/c/sJQ3\nvPvzAGwycwO+8YkjePDB4tYFd3DYu04acO81tKZKBTPBUlX9uXByKrA3MAu4HTimqj472md23312\nXXSJ+9lI/TJzjzcPugtSpy2+6nQevHd+R0sG2OnJT6vPfe17E37dZzxh5k+ravaEX3gV9C0hqqpD\n+nVtSZI0GO5ULUmS1FHOIZIkSa11dNW9BZEkSWqvo/WQQ2aSJEkmRJIkqb2ORkQmRJIkaeiZEEmS\npFZ6O0t3MyKyIJIkSe2ku6vMHDKTJElDz4RIkiS11tGAyIRIkiTJhEiSJLXX0YjIhEiSJA09EyJJ\nktRSXHYvSZLksntJkqSOMiGSJEmthM7OqTYhkiRJMiGSJEntdTQisiCSJEmtdXWVmUNmkiRp6JkQ\nSZKk1lx2L0mS1FEmRJIkqbWOBkQWRJIkqaUOb0TkkJkkSRp6JkSSJKk1l91LkiR1lAmRJElqJbjs\nXpIkqbNMiCRJUmsdDYgsiCRJ0iroaEXkkJkkSRp6JkSSJKk1l91LkiR1lAmRJElqzWX3kiRp6KUP\nr1b3TTZK8uUkv07yqyTPSLJxkvOTXNP8OXO838uCSJIkrQ4+CpxbVU8EdgV+BRwFXFBV2wMXNO/H\nxYJIkiS1N4CIKMmGwHOAzwJU1f1VdQdwAHBSc9pJwIHj/VoWRJIkadBmJZkz4nX4cse3AxYAn0vy\nsySfSbIesFlV3dac81tgs/F2wEnVkiSplV6g05dZ1QuravYox2cAuwFvqapLknyU5YbHqqqS1Hg7\nYEIkSZLaSW+V2US/WpgHzKuqS5r3X6ZXIN2e5LEAzZ/zx/vVLIgkSdKUVlW/BW5OsmPT9Hzgl8BZ\nwKFN26HA18d7D4fMJElSawPchugtwBeSrAlcD7yOXrBzepLDgBuBg8Z7cQsiSZI05VXV5cCK5hk9\nfyKub0EkSZLac6dqSZKkbjIhkiRJLaWzT7u3IJIkSa35cFdJkqSOMiGSJEmtrMrT6Vc3JkSSJGno\nmRBJkqT2OhoRWRBJkqTWurrKzCEzSZI09EyIJElSay67lyRJ6igTIkmS1FpHAyILIkmS1FIcMpMk\nSeosEyJJkrQKuhkRmRBJkqShZ0IkSZJaCc4hkiRJ6iwTIkmS1FpHAyILIkmS1J5DZpIkSR1lQiRJ\nklrzafeSJEkdZUIkSZLa62ZAZEEkSZLa62g95JCZJEmSCZEkSWolPu1ekiSpu0yIJElSa11ddm9B\nJEmS2utVUcz7AAAFaklEQVRmPeSQmSRJkgmRJElqraMBkQmRJEmSCZEkSWrNZfeSJEkdZUIkSZJa\nisvuJUnScAsOmUmSJHWWBZEkSRp6FkSSJGnoOYdIkiS11tU5RBZEkiSpta6uMnPITJIkDT0TIkmS\n1E66O2RmQiRJkoaeCZEkSWoldPdp9xZEkiSpvY5WRA6ZSZKkoWdCJEmSWnPZvSRJUkeZEEmSpNZc\ndi9JktRRJkSSJKm1jgZEFkSSJGkVdLQicshMkiQNPRMiSZLUmsvuJUmSOsqESJIktRK6u+w+VTXo\nPjwkyQLgxkH3Q63NAhYOuhNSx/n3bPWyTVVtMuhO9EuSc+n9b3KiLayqfftw3damVEGk1UuSOVU1\ne9D9kLrMv2fS5HAOkSRJGnoWRJIkaehZEOmR+NSgOyANAf+eSZPAOUSSJGnomRBJkqShZ0GkcUmy\nb5Krklyb5KhB90fqmiQnJJmf5MpB90UaBhZEWmVJpgPHA/sBOwOHJNl5sL2SOudEYKD7skjDxIJI\n47EncG1VXV9V9wOnAQcMuE9Sp1TVhcCiQfdDGhYWRBqPLYCbR7yf17RJkrRasiCSJElDz4JI43EL\nsNWI91s2bZIkrZYsiDQelwLbJ9kuyZrAwcBZA+6TJEnjZkGkVVZVS4A3A+cBvwJOr6q5g+2V1C1J\nTgUuBnZMMi/JYYPuk9Rl7lQtSZKGngmRJEkaehZEkiRp6FkQSZKkoWdBJEmShp4FkSRJGnoWRFIf\nJVma5PIkVyY5I8m6j+Baeyf5ZvPzS5IcNcq5GyX523Hc4z1J3ta2fblzTkzyV6twr219krukqcKC\nSOqv+6rqqVX1JOB+4I0jD6Znlf8eVtVZVXXcKKdsBKxyQSRJw8qCSJo8PwSe0CQjVyU5GbgS2CrJ\nC5NcnOSyJklaHyDJvkl+neQy4GXLLpTktUk+3vy8WZKvJrmieT0TOA54fJNOfbA575+SXJrk50ne\nO+Ja70xydZIfATuO9SWS/E1znSuSfGW51OsFSeY019u/OX96kg+OuPf/fqS/SEmaaBZE0iRIMgPY\nD/hF07Q98Imq2gW4B3gX8IKq2g2YAxyZZG3g08BfArsDj1nJ5T8G/KCqdgV2A+YCRwHXNenUPyV5\nYXPPPYGnArsneU6S3ek9euWpwF8Ae7T4OmdW1R7N/X4FjNxBedvmHi8GPtl8h8OAO6tqj+b6f5Nk\nuxb3kaRJM2PQHZA6bp0klzc//xD4LLA5cGNV/bhp3wvYGbgoCcCa9B7Z8ETghqq6BiDJKcDhK7jH\n84DXAFTVUuDOJDOXO+eFzetnzfv16RVIGwBfrap7m3u0eSbdk5L8C71hufXpPcJlmdOr6kHgmiTX\nN9/hhcBTRswv2rC599Ut7iVJk8KCSOqv+6rqqSMbmqLnnpFNwPlVdchy5z3sc49QgPdX1X8td49/\nGMe1TgQOrKorkrwW2HvEseWfBVTNvd9SVSMLJ5JsO457S1JfOGQmDd6PgWcleQJAkvWS7AD8Gtg2\nyeOb8w5ZyecvAN7UfHZ6kg2Bu+mlP8ucB7x+xNykLZJsClwIHJhknSQb0BueG8sGwG1J1gBeudyx\nlyeZ1vT5ccBVzb3f1JxPkh2SrNfiPpI0aUyIpAGrqgVN0nJqkrWa5ndV1dVJDgfOTnIvvSG3DVZw\nib8HPtU8DX0p8KaqujjJRc2y9m8184h2Ai5uEqo/AK+qqsuSfAm4ApgPXNqiy/8XuARY0Pw5sk83\nAT8BHgW8sar+mOQz9OYWXZbezRcAB7b77UjS5PBp95Ikaeg5ZCZJkoaeBZEkSRp6FkSSJGnoWRBJ\nkqShZ0EkSZKGngWRJEkaehZEkiRp6FkQSZKkoff/AbLYsk1SBQ/uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb512402748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.45, min_samples_leaf=7, min_samples_split=19)\n",
    "\n",
    "skplt.classifiers.plot_confusion_matrix(clf, X, y, normalize=False, title='Confusion Matrix', cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempts</th>\n",
       "      <th>comments</th>\n",
       "      <th>blank_line</th>\n",
       "      <th>lloc</th>\n",
       "      <th>sloc</th>\n",
       "      <th>single_comments</th>\n",
       "      <th>system_access</th>\n",
       "      <th>exam_grade_codebench</th>\n",
       "      <th>difficult</th>\n",
       "      <th>delete_average</th>\n",
       "      <th>...</th>\n",
       "      <th>submission_per_exercice</th>\n",
       "      <th>sucess_average</th>\n",
       "      <th>test_average</th>\n",
       "      <th>exercices_list_grade</th>\n",
       "      <th>exercices_list_grade_check_plagiarism</th>\n",
       "      <th>copy_past_proportion</th>\n",
       "      <th>sintaxe_error</th>\n",
       "      <th>IDE_usage</th>\n",
       "      <th>keystroke_latency</th>\n",
       "      <th>Media_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>...</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>372.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.11</td>\n",
       "      <td>9.42</td>\n",
       "      <td>12.34</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.19</td>\n",
       "      <td>10.03</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.93</td>\n",
       "      <td>7.30</td>\n",
       "      <td>...</td>\n",
       "      <td>12.33</td>\n",
       "      <td>2.44</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.18</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1.99</td>\n",
       "      <td>6.30</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attempts  comments  blank_line    lloc    sloc  single_comments  \\\n",
       "count    372.00    372.00      372.00  372.00  372.00           372.00   \n",
       "mean      -0.00      0.00        0.00    0.00   -0.00             0.00   \n",
       "std        1.00      1.00        1.00    1.00    1.00             1.00   \n",
       "min       -0.84     -0.34       -0.52   -0.68   -0.69            -0.34   \n",
       "25%       -0.51     -0.34       -0.46   -0.48   -0.48            -0.34   \n",
       "50%       -0.28     -0.33       -0.30   -0.29   -0.29            -0.33   \n",
       "75%        0.19     -0.15        0.05    0.16    0.17            -0.13   \n",
       "max       10.11      9.42       12.34   11.33   11.19            10.03   \n",
       "\n",
       "       system_access  exam_grade_codebench  difficult  delete_average  \\\n",
       "count         372.00                372.00     372.00          372.00   \n",
       "mean            0.00                 -0.00       0.00           -0.00   \n",
       "std             1.00                  1.00       1.00            1.00   \n",
       "min            -1.25                 -1.26      -3.15           -0.80   \n",
       "25%            -0.76                 -1.01      -0.66           -0.69   \n",
       "50%            -0.27                  0.25       0.25           -0.27   \n",
       "75%             0.47                  0.66       0.93            0.25   \n",
       "max             4.90                  1.50       0.93            7.30   \n",
       "\n",
       "          ...       submission_per_exercice  sucess_average  test_average  \\\n",
       "count     ...                        372.00          372.00        372.00   \n",
       "mean      ...                         -0.00           -0.00         -0.00   \n",
       "std       ...                          1.00            1.00          1.00   \n",
       "min       ...                         -0.30           -0.99         -0.77   \n",
       "25%       ...                         -0.28           -0.99         -0.69   \n",
       "50%       ...                         -0.20           -0.24         -0.35   \n",
       "75%       ...                         -0.04            0.52          0.27   \n",
       "max       ...                         12.33            2.44          5.00   \n",
       "\n",
       "       exercices_list_grade  exercices_list_grade_check_plagiarism  \\\n",
       "count                372.00                                 372.00   \n",
       "mean                   0.00                                  -0.00   \n",
       "std                    1.00                                   1.00   \n",
       "min                   -1.98                                  -1.48   \n",
       "25%                   -0.53                                  -0.89   \n",
       "50%                    0.67                                  -0.00   \n",
       "75%                    0.67                                   1.03   \n",
       "max                    0.67                                   1.18   \n",
       "\n",
       "       copy_past_proportion  sintaxe_error  IDE_usage  keystroke_latency  \\\n",
       "count                372.00         372.00     372.00             372.00   \n",
       "mean                   0.00           0.00       0.00               0.00   \n",
       "std                    1.00           1.00       1.00               1.00   \n",
       "min                   -0.13          -1.12      -1.02              -1.66   \n",
       "25%                   -0.13          -0.75      -0.80              -0.48   \n",
       "50%                   -0.13          -0.35      -0.17               0.19   \n",
       "75%                   -0.13           0.37       0.44               0.69   \n",
       "max                   13.65           1.99       6.30               3.03   \n",
       "\n",
       "       Media_Final  \n",
       "count       372.00  \n",
       "mean          0.56  \n",
       "std           0.50  \n",
       "min           0.00  \n",
       "25%           0.00  \n",
       "50%           1.00  \n",
       "75%           1.00  \n",
       "max           1.00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>TODO </font>\n",
    "\n",
    "* Remover outiliers por grupo usando IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
